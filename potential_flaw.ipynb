{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638fb31-fa0d-4e4f-91be-b7ebb1563dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558513f4-6f13-45d3-9c30-1a9079de5d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b968171-edd1-41a0-b9a7-044ebbcfe68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63199a2b-ea47-4aa5-9770-3bd5b3e0ce53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b16f7f-f98e-486a-a308-c74607ee36b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78145b02-c441-457a-b70b-80baa5f1195b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eab83a-c183-4fd3-a6c4-fe89b1e56f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1179c6b-efbb-4683-90b9-cf5291ddd66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0a1c1-6892-48fa-9dae-c8fc6f987d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa3d009-99ad-4880-93d4-9e192d6ae15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph \n",
    "\n",
    "adjacency_matrix = np.array([\n",
    "    [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
    "])\n",
    "\n",
    "graph = nx.from_numpy_array(adjacency_matrix)\n",
    "laplacian = nx.normalized_laplacian_matrix(graph).toarray()\n",
    "_, eigvects = np.linalg.eigh(laplacian) # sorted eigenvalue/eigenvector pairs\n",
    "\n",
    "np.random.seed(42)\n",
    "graph = nx.from_numpy_array(adjacency_matrix)\n",
    "\n",
    "nx.draw(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0152fa-79ec-42ce-8875-8c1d0a3b8054",
   "metadata": {},
   "source": [
    "<p>has a zero in the largest eigenvector : </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3921a-12e1-4f7c-8426-eff0fdaaf9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvects[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e6a9c-73c0-449e-9462-43f0eea5fe26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e74b286-b93d-4902-9758-399f70fe6385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc13ecc-891d-42c6-881b-bcef38220ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = -eigvects[-2, -1] / eigvects[-1, -1]\n",
    "x = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, coeff]\n",
    "x_hat = np.linalg.inv(eigvects) @ x \n",
    "\n",
    "x_hat # last entry is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c8dea-e688-471c-b492-619d10bc6685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61468afa-41f5-496a-9ede-2d9590858e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b393e-ec8b-4212-acd8-d34f4a6dabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_node_values = -eigvects[:, 0]\n",
    "true_coefficients = [-1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "target_node_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cbfce8-731f-4193-bf66-61a14793450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "nx.draw(graph, node_color=target_node_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cddeac-57a1-4a93-846b-5269bfd843b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c2bae-7b57-4b86-974a-243b4ce83000",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Small choice for visualization purposes\n",
    "bad_coeff = true_coefficients + 0.25 * x_hat\n",
    "bad_node_values = eigvects @ bad_coeff\n",
    "\n",
    "\n",
    "# Observe that the first 7 node values do not change\n",
    "bad_node_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c155c-5876-4a13-8683-e7b52bb90879",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clearly has the same two persistence points\n",
    "np.random.seed(42)\n",
    "nx.draw(graph, node_color=bad_node_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d104bd7-724f-4571-843d-e4bfe6af5f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we can do much worse, since we are scaling the last node by a factor of 1.33 and \n",
    "# the second to last node by a value of only 1. \n",
    "\n",
    "worse_coeff = true_coefficients + 10000 * x_hat\n",
    "worse_node_values = eigvects @ worse_coeff\n",
    "worse_node_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96881560-2937-4d06-a5f8-9f32a38e7124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d73b20-d442-438a-a218-7f652ecb414a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba8e29-e186-4d77-8960-7402cf123a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 19\n",
    "\n",
    "GU = nx.cycle_graph(num_nodes)\n",
    "np.random.seed(5)\n",
    "\n",
    "GU.add_edge(0,2)  # will add a persistence point for our choice of node values\n",
    "GU.add_edge(3,5) # will add a persistence point for our choice of node_values\n",
    "GU.add_edge(6,8) # and so on ...\n",
    "GU.add_edge(9, 11)\n",
    "\n",
    "nx.draw(GU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e98eefe-b79b-406b-8f5e-580b732a511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GU_laplacian = nx.normalized_laplacian_matrix(GU).toarray()\n",
    "_, GU_eigvects = np.linalg.eigh(GU_laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9bf14-64b5-448f-94e1-a840a3151eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gu_target_node_values = np.abs(GU_eigvects[:, 0])\n",
    "\n",
    "np.random.seed(5)\n",
    "nx.draw(GU, node_color=gu_target_node_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78568a7-bea8-4615-a089-f378268abacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GU_eigvects[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eca7e7-f10d-41e3-90e3-f01d25f04545",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.abs(GU_eigvects[:, -1][-2] / GU_eigvects[:, -1][-1]) \n",
    "x = np.zeros(num_nodes)\n",
    "x[-2:] = np.array([1.0, alpha])\n",
    "\n",
    "x_hat = np.linalg.inv(GU_eigvects) @ x # last entry is zero\n",
    "x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac7095-d734-4190-b4c1-bfddd944f947",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = np.zeros(19)\n",
    "base[0] = -1.0\n",
    "\n",
    "sltn = base + 0.1 * x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b48142-b39e-4eae-bc83-bb682769f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_node_values = GU_eigvects @ sltn\n",
    "\n",
    "np.random.seed(5)\n",
    "nx.draw(GU, node_color=bad_node_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9fd83-bc21-4979-a2d8-4b6d8cd7c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_node_values # and this will have the same persistence diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca5c1c-5316-4d18-b524-8bfbd888f723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022c79f-cab9-4caa-8a0c-4ba77e2b1d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b482b5d-eb84-41fa-96b6-397eefd7db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # for kde\n",
    "import scipy # for sparse arrays\n",
    "\n",
    "# Ripser allows us to use a sparse filtration to compute PH. \n",
    "import ripser \n",
    "from gudhi.wasserstein import wasserstein_distance\n",
    "\n",
    "import tqdm # for showing progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ccf391-37f0-461e-9ef0-6a17f4103ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_wasserstein(dgmx, dgmy, gamma):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the 2-wasserstein distance between persistence diagrams dgmx and dgmy, \n",
    "    and scale by a factor of gamma. \n",
    "    \n",
    "    Gudhi's wasserstein doesn't handle cases where one of the diagrams has\n",
    "    only one persistence point, so it has to be done manually.\n",
    "    \"\"\"\n",
    "\n",
    "    l1 = dgmx.shape\n",
    "    l2 = dgmy.shape\n",
    "\n",
    "    # First diagram has more than one persistence point\n",
    "    if l1 != (2,):\n",
    "        \n",
    "        # So does the second diagram, normal wasserstein distance works\n",
    "        if l2 != (2,):\n",
    "            return -gamma * wasserstein_distance(dgmx, dgmy, False, 2.0, 2.0)\n",
    "        \n",
    "        # Otherwise dgmy has only one persistence point, have to compute manually\n",
    "        # Unsure if this step is right ??? \n",
    "        else:\n",
    "            infinite_cost = (dgmx[-1, 0] - dgmy[0]) ** 2\n",
    "            diagonal_cost = (dgmx[:-1, 1] - dgmx[:-1, 0]) * 0.5\n",
    "            return -gamma * np.sqrt(infinite_cost + np.sum(diagonal_cost))\n",
    "\n",
    "    # First diagram only has one persistence point\n",
    "    else:\n",
    "        # Second diagram has more than one persistance point, we compute manually.\n",
    "        if l2 != (2,):\n",
    "            infinite_cost = (dgmx[0] - dgmy[-1,0]) ** 2\n",
    "            diagonal_cost = (dgmy[:-1, 1] - dgmy[:-1, 0]) * 2 * 0.5\n",
    "            return -gamma * np.sqrt(infinite_cost + np.sum(diagonal_cost))\n",
    "        \n",
    "        # Both diagrams only have one persistence point, the distance is the di\n",
    "        else:\n",
    "            return -gamma *np.abs(dgmx[0] - dgmy[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e347d-ab54-4d51-a4dc-6c82e5ea4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphPersistenceGenerator:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    This class works in the following way:\n",
    "        \n",
    "        We rely on the creation of a custom filtration to preform persistent homology computations.\n",
    "        This filtration takes the form of a matrix which inherits the structure of G, i.e.  \n",
    "    \n",
    "        The diagonal of this matrix will be given by node values. If G has an edge between nodes \n",
    "        (i,j), then we set filtration[i,j] to be the maximum node value between i and j. If there is not\n",
    "        an edge between nodes (i,j), then we treat the \"distance\" as infinite.\n",
    "\n",
    "        Persistent homology calculations are \n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, G):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize the adjacency matrix\n",
    "        G : networkx graph\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        adj = nx.adjacency_matrix(G)\n",
    "        h, w = adj.shape\n",
    "        \n",
    "        # Get indices of edges, determined by the structure on G\n",
    "        # edge_idx, edge_idy = adj.nonzero(). Of course, the adjacency matrix is symmertric; \n",
    "        # for efficiency, we choose to remember only the lower diagonal indcies to update the filtration. \n",
    "\n",
    "        inds = np.vstack([*adj.nonzero()]).T\n",
    "\n",
    "        full_edge_idx, full_edge_idy = inds[:, 0], inds[:, 1]\n",
    "        \n",
    "        lower_diag_inds = inds[np.argmax(inds, axis=1) > 0, :]\n",
    "        edge_idx, edge_idy = lower_diag_inds[:, 0], lower_diag_inds[:, 1]\n",
    "        \n",
    "        # Indices of nodes, which are on the diagonal of the filtration matrix \n",
    "        node_idx, node_idy = np.arange(0,h), np.arange(0,h)\n",
    "\n",
    "        # Combined indices of edges and nodes. Note that we need to account for the symmetry of the adjacency\n",
    "        # matrix here, which is why we are using the full_edge_idx and full_edge_idy here.\n",
    "        idx_x, idx_y = np.concatenate([full_edge_idx, node_idx]), np.concatenate([full_edge_idy, node_idy])\n",
    "        self.filtration_inds = list(zip(np.concatenate([edge_idx, node_idx]), np.concatenate([edge_idy, node_idy])))\n",
    "        \n",
    "        self.filtration = scipy.sparse.csr_matrix((np.ones(len(idx_x)), (idx_x, idx_y)), shape=(h,w))\n",
    "\n",
    "    def update(self, new_node_values):\n",
    "        \n",
    "        \"\"\"\n",
    "        Update edge weights/node values with new_node_values\n",
    "        For example, suppose the current state of self.filtration is \n",
    "        \n",
    "        [[0.1, 0.4, 0.0], \n",
    "         [0.4, 0.4, 0.4],\n",
    "         [0.0, 0.4, 0.1]]\n",
    "        \n",
    "        and the indicies we replace are specified as [[0,0], [0,1], [1,1], [2,1], [2,2]].\n",
    "        \n",
    "        If new_node_values = [0.05, 0.1, 0.25], \n",
    "        calling self.update() will change self.filtration to\n",
    "        \n",
    "        [[0.05, 0.1, 0.0], \n",
    "         [0.1, 0.1, 0.25],\n",
    "         [0.0, 0.25, 0.25]]\n",
    "\n",
    "\n",
    "        Note that for a given edge in the filtration, which is specified by indices [i,j], the \n",
    "        edge will be \"created\" at max(node_value(i), node_value(j)) when we want to \n",
    "        calculate the persistence diagram of the graph. \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        for (i,j) in self.filtration_inds:\n",
    "            new_edge_weight = np.maximum(new_node_values[i], new_node_values[j])\n",
    "            self.filtration[i,j] = new_edge_weight\n",
    "            self.filtration[j,i] = new_edge_weight\n",
    "        \n",
    "        \n",
    "    def compute_PH(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Compute the 0-dimensional persistent homology for the current filtration.\n",
    "        \n",
    "        Ripser returns a list of persistence diagram points, which we need to convert to a 2-D numpy array to\n",
    "        use in gudhi's wasserstein_distance function.\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.squeeze(np.array(ripser.ripser(self.filtration, maxdim=0, distance_matrix=True)['dgms']))\n",
    "\n",
    "\n",
    "    def __call__(self, new_node_values):\n",
    "        self.update(new_node_values)\n",
    "        return self.compute_PH()\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8f7ee-2d79-4a13-a8bb-b7a2a9d2305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EigenvectorRandomWalkMetropolis:\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Graph laplacian eigenvector Random Walk Metropolis Class\n",
    "    \n",
    "    parameters: \n",
    "\n",
    "        G : networkx graph\n",
    "        \n",
    "        target : the target persistence diagram (n x 2 numpy array)\n",
    "        \n",
    "        start : the starting point for mcmc\n",
    "\n",
    "        step : Proposed moves follow a normal distribution with mean = 0 and std = step.\n",
    "        \n",
    "        nev : number of graph laplacian eigenvectors to take - this is the dimension \n",
    "              of the search space\n",
    "              \n",
    "        MIN/MAX : bounds of the search space \n",
    "\n",
    "        \n",
    "        gamma : scaling factor for 2-wasserstein distance\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, G, target, start, step, nev, MIN=-np.inf, MAX=np.inf, gamma=1.0):\n",
    "\n",
    "        laplacian = nx.normalized_laplacian_matrix(G).toarray()\n",
    "        _, eigenvectors = np.linalg.eigh(laplacian)\n",
    "\n",
    "        self.phi = eigenvectors[:, 0:nev]\n",
    "        self.gpg = GraphPersistenceGenerator(G)\n",
    "        self.target = target\n",
    "        self.current_location = start\n",
    "        self.step = step\n",
    "        self.gamma = gamma\n",
    "        self.nev = nev\n",
    "        self.current_p = self.density_func(start)\n",
    "        self.num_accepted = 0\n",
    "        self.lower_bound = MIN\n",
    "        self.upper_bound = MAX\n",
    "\n",
    "    def density_func(self, x):\n",
    "\n",
    "        \"\"\" \n",
    "        \n",
    "        x is assumed to be a vector of coefficients in this case, but\n",
    "        different varieties of density functions can replace this\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        output_pd = self.gpg(self.phi @ x)\n",
    "        return two_wasserstein(output_pd, self.target, self.gamma)\n",
    "    \n",
    "    def sample(self):\n",
    "\n",
    "        \"\"\"Preform one iteration of MCMC\"\"\"\n",
    "        \n",
    "        proposed_move = np.random.normal(loc=0.0, scale=step, size=self.nev) + self.current_location\n",
    "        if np.all(proposed_move >= self.lower_bound) & np.all(proposed_move <= self.upper_bound):\n",
    "            proposed_move_density = self.density_func(proposed_move)\n",
    "            \n",
    "            if np.random.uniform() < np.exp(proposed_move_density - self.current_p):\n",
    "                \n",
    "                # the move is accepted, update the current location and density, and\n",
    "                # increment the numeber of accepted moves by one.\n",
    "                self.current_p = proposed_move_density\n",
    "                self.current_location = proposed_move\n",
    "                self.num_accepted += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251dcf06-ea3e-41ce-9b83-294ea772c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMC:\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Runs MCMC over multiple iterations, and keeps track of paramter locations and densities. \n",
    "    Also inlcudes functionality for plotting trace plots \n",
    "\n",
    "        - model should be one of the RWM models in this file.\n",
    "        - dim is the dimension of the search space\n",
    "        - gamma is the 2-wasserstein penalty term used in the density function, defaults to 1.0\n",
    "        - iterations - number of mcmc iterations to run\n",
    "        - burnin - burnin period\n",
    "        - seed - random seed for reproducibility.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, dim, gamma=1.0, iterations=100000, burnin=10000, seed=42):\n",
    "\n",
    "        self.model = model\n",
    "        \n",
    "        self.iterations = iterations\n",
    "        self.burnin = burnin\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        self.seed = seed\n",
    "\n",
    "        self.sim = np.zeros((dim, iterations-burnin))\n",
    "        self.losses = np.zeros(iterations-burnin)\n",
    "\n",
    "        # If we are using a penalty term when calculating the 2-wasserstein distance, include it\n",
    "        # here to scale densities to calculate various performance metrics.\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def run(self):\n",
    "\n",
    "        \"\"\" \n",
    "        Run MCMC for the specified number of iterations\n",
    "        \"\"\"\n",
    "        \n",
    "        np.random.seed(self.seed)\n",
    "        for i in tqdm.tqdm(range(self.iterations)):\n",
    "\n",
    "            self.model.sample()\n",
    "\n",
    "            if i - self.burnin >= 0:\n",
    "                self.sim[:, i - burnin] = model.current_location\n",
    "                self.losses[i - burnin] = - model.current_p / self.gamma\n",
    "\n",
    "        print(f\"Percentage of moves accepted : {model.num_accepted / self.iterations * 100.0} %\")\n",
    "        print(f\"Best Loss: {np.min(self.losses)}\")\n",
    "\n",
    "\n",
    "    \n",
    "    def trace_plots(self, inds=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Create trace plots\n",
    "        \n",
    "        inds : the parameters you want to see trace plots for - e.g, if you have \n",
    "               8 parameters, and you pass [0,1,2,3] to trace_plots, you will see \n",
    "               trace plots for the first 4 parameters. \n",
    "\n",
    "               Passing None will result in all trace plots being shown\n",
    "        \n",
    "        \"\"\"    \n",
    "        \n",
    "        if inds:\n",
    "            fig, axes = plt.subplots(len(inds), 1, layout='constrained')\n",
    "        else:\n",
    "            inds = range(self.sim.shape[0])\n",
    "            fig, axes = plt.subplots(self.sim.shape[0], 1, layout='constrained')\n",
    "        \n",
    "        for (i,indx) in enumerate(inds):\n",
    "            sns.lineplot(data=self.sim[i, :], ax=axes[i])        \n",
    "      \n",
    "        plt.show()\n",
    "\n",
    "    def density_plots(self, inds=None):\n",
    "        \"\"\"Create density plots, inds functions the same as in trace_plots\"\"\"\n",
    "        \n",
    "        if inds:\n",
    "            fig, axes = plt.subplots(len(inds), 1, layout='constrained')\n",
    "        else:\n",
    "            inds = range(self.sim.shape[0])\n",
    "            fig, axes = plt.subplots(self.sim.shape[0], 1, layout='constrained')\n",
    "        \n",
    "        for (i,indx) in enumerate(inds):\n",
    "            sns.kdeplot(data=self.sim[i, :], ax=axes[i]) \n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    # def best_approximation(self):\n",
    "    #     \"\"\"Return the node values of the best apporximation found in the run\"\"\"\n",
    "    #     min_loss = np.argmin(self.losses)\n",
    "    #     best_coeff = self.sim[:, min_loss]\n",
    "    #     best_node_values = self.model.phi @ best_coeff\n",
    "\n",
    "    #     return best_node_values\n",
    "\n",
    "    # def plot_pds(self, node_values=None):\n",
    "    #     \"\"\"TODO\"\"\"\n",
    "        \n",
    "    #     if node_values:\n",
    "    #         pd_out = self.model.gpg(node_values)\n",
    "    #     else:\n",
    "    #         node_values = self.best_approximation()\n",
    "    #         pd_out = self.model.gpg(node_values)\n",
    "\n",
    "\n",
    "    #     pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2b07a-4451-4508-ba86-20e5fdb6ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distribution_matrix(node_values, sort=True):\n",
    "    \"\"\"\n",
    "    \n",
    "    Example: \n",
    "\n",
    "    Suppose our node values are [0.1, 0.2, 0.1, 0.5]. Then \n",
    "    generate_distribution_matrix([0.1, 0.2, 0.1, 0.5]) returns\n",
    "\n",
    "    [ 0.1, 0.2, 0.1, 0.5 ]\n",
    "    [ 0.1, 0.2, 0.1, 0.5 ]\n",
    "    [ 0.1, 0.2, 0.1, 0.5 ]\n",
    "    [ 0.1, 0.2, 0.1, 0.5 ]\n",
    "\n",
    "\n",
    "    and we can also choose to sort the node values by passing sort=True\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(node_values)\n",
    "\n",
    "    if sort:\n",
    "        return np.repeat(np.sort(node_values), n).reshape((n,n))\n",
    "    else:\n",
    "        return np.repeat(node_values, n).reshape((n,n))\n",
    "    \n",
    "\n",
    "class DiscreteRandomWalkMetropolis:\n",
    "\n",
    "    # def __init__(self, G, target_node_values, start, gamma=1.0, sort=True):\n",
    "    def __init__(self, G, distribution, target, start, gamma):\n",
    "    \n",
    "        # Graph persistence diagram generator\n",
    "        self.gpg = GraphPersistenceGenerator(G)\n",
    "        # self.target = self.gpg(target_node_values)\n",
    "        self.target = target\n",
    "\n",
    "        # distribution = generate_distribution_matrix(target_node_values, sort)\n",
    "        self.distribution = distribution\n",
    "\n",
    "        # Place hard limits on possible index values.\n",
    "        self.lower_bound = 0\n",
    "        self.upper_bound = self.distribution.shape[0] - 1\n",
    "        self.column_inds = range(len(G.nodes))\n",
    "\n",
    "        self.current_location = start\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.current_p = self.density_func(start) \n",
    "\n",
    "        self.num_accepted = 1\n",
    "    \n",
    "    def density_func(self, x):\n",
    "        new_node_values = self.distribution[x, self.column_inds]\n",
    "        output_pd = self.gpg(new_node_values)\n",
    "        return two_wasserstein(output_pd, self.target, self.gamma)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        \n",
    "        Example:\n",
    "\n",
    "        Lets say our distribution matrix is given by \n",
    "\n",
    "        D = \n",
    "\n",
    "        [ 0.54 0.54 0.54 0.54 ]\n",
    "        [ 0.12 0.12 0.12 0.12 ]\n",
    "        [ 0.43 0.43 0.43 0.43 ]\n",
    "        [ 0.25 0.25 0.25 0.25 ] \n",
    "\n",
    "        and our current location is [0, 1, 1, 0], i.e, we are at node values \n",
    "        \n",
    "        D[0,0] = 0.54, D[1,1] = 0.12, D[1,2] = 0.12, D[0,3] = 0.54,     [0.54, 0.12, 0.12, 0.54]\n",
    "\n",
    "        We can then search across the parameter space by incrementing/decrementing/staying constant \n",
    "        on each index in our current location. Given our current location of [0, 1, 1, 0], we could then \n",
    "        move to [0, 1, 1, 0] + [0, -1, 1, 1] = [0, 0, 2, 1], which would give us node values of\n",
    "\n",
    "        D[0,0] = 0.54, D[0,1] = 0.54, D[2,2] = 0.43, D[1,3] = 0.12,     [0.54, 0.54, 0.43, 0.12]\n",
    "\n",
    "        From here, we can calculate a persistence diagram of a graph with these node values, and get a density. \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        proposed_move = self.current_location + np.random.choice([-1, 0, 1], len(self.column_inds))\n",
    "        if np.all(proposed_move >= self.lower_bound) & np.all(proposed_move <= self.upper_bound):\n",
    "            proposed_move_density = self.density_func(proposed_move)\n",
    "            \n",
    "            if np.random.uniform() < np.exp(proposed_move_density - self.current_p):\n",
    "                \n",
    "                # the move is accepted, update the current location and density, and\n",
    "                # increment the numeber of accepted moves by one.\n",
    "                self.current_p = proposed_move_density\n",
    "                self.current_location = proposed_move\n",
    "                self.num_accepted += 1\n",
    "\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d01632-fbdf-4f9d-b85c-696564b22b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100000\n",
    "burnin = 10000\n",
    "gamma = 40.0\n",
    "seed = 44\n",
    "\n",
    "num_nodes = 10\n",
    "node_prob = 0.2\n",
    "\n",
    "np.random.seed(seed)\n",
    "G = nx.erdos_renyi_graph(num_nodes, node_prob, seed=seed)\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f206b1-43f4-4a76-b982-bc31c07b90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "node_values_hat = np.random.rand(num_nodes)\n",
    "gpg = GraphPersistenceGenerator(G)\n",
    "target = gpg(node_values_hat)\n",
    "print(target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7578a8-ceb9-4eea-b464-71a695434d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit possible node values to only birth/death values in the target persistence diagram\n",
    "distribution_node_values = np.unique(target)[:-1]\n",
    "distribution = np.repeat(distribution_node_values, num_nodes).reshape((len(distribution_node_values), num_nodes))\n",
    "start = np.random.randint(0, distribution.shape[0], distribution.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa7b9a1-a70b-4de4-9a0d-c03762d093c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  G, distribution, target, start, gamma\n",
    "model = DiscreteRandomWalkMetropolis(G, distribution, target, start, gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61b9c06-675f-4c7d-b1f3-ebcbca419db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation = MCMC(model, num_nodes, gamma, iterations, burnin, seed)\n",
    "simulation.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cbf906-aee3-4486-b618-b19572cca33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_coeff_idx = np.argmin(simulation.losses)\n",
    "best_indices = simulation.sim[:, best_coeff_idx]\n",
    "best_node_values = distribution[best_indices.astype(np.int64), range(num_nodes)]\n",
    "\n",
    "best_pd = gpg(best_node_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b28722-c867-40f0-a986-77a4f0a33d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "nx.draw(G, node_color = node_values_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c41fce-9e82-4955-8444-7eb76705018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "nx.draw(G, node_color = best_node_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8e9ce-a097-47b2-b688-25addaaed6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1cd9c-794e-4ac2-9c77-004db9b0099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b71913-b20b-4401-ae0d-4da5b705dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.trace_plots([0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1cc1ee-7cad-4202-952a-34359d85786f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9a726-5bed-4034-8d9f-9d262d19d5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d923de-b73d-428f-b2f8-eb43e951e7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b2c85-1c8b-4e60-ad5d-c0cfa9461890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce7924-1f39-4967-bc6b-906e19c78212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
