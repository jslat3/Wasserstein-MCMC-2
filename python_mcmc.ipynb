{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866fd30c-6e5b-40a6-a776-6f5d76563f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # for kde\n",
    "import scipy # for sparse arrays\n",
    "\n",
    "# Ripser allows us to use a sparse filtration to compute PH. \n",
    "import ripser \n",
    "from gudhi.wasserstein import wasserstein_distance\n",
    "\n",
    "import tqdm # for showing progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396343b-69ca-47c1-b2db-eb1376340a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_wasserstein(dgmx, dgmy, gamma):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the 2-wasserstein distance between persistence diagrams dgmx and dgmy, \n",
    "    and scale by a factor of gamma. \n",
    "    \n",
    "    Gudhi's wasserstein doesn't handle cases where one of the diagrams has\n",
    "    only one persistence point, so it has to be done manually.\n",
    "    \"\"\"\n",
    "\n",
    "    l1 = dgmx.shape\n",
    "    l2 = dgmy.shape\n",
    "\n",
    "    # First diagram has more than one persistence point\n",
    "    if l1 != (2,):\n",
    "        \n",
    "        # So does the second diagram, normal wasserstein distance works\n",
    "        if l2 != (2,):\n",
    "            return -gamma * wasserstein_distance(dgmx, dgmy, False, 2.0, 2.0)\n",
    "        \n",
    "        # Otherwise dgmy has only one persistence point, have to compute manually\n",
    "        # Unsure if this step is right ??? \n",
    "        else:\n",
    "            infinite_cost = (dgmx[-1, 0] - dgmy[0]) ** 2\n",
    "            diagonal_cost = (dgmx[:-1, 1] - dgmx[:-1, 0]) * 0.5\n",
    "            return -gamma * np.sqrt(infinite_cost + np.sum(diagonal_cost))\n",
    "\n",
    "    # First diagram only has one persistence point\n",
    "    else:\n",
    "        # Second diagram has more than one persistance point, we compute manually.\n",
    "        if l2 != (2,):\n",
    "            infinite_cost = (dgmx[0] - dgmy[-1,0]) ** 2\n",
    "            diagonal_cost = (dgmy[:-1, 1] - dgmy[:-1, 0]) * 2 * 0.5\n",
    "            return -gamma * np.sqrt(infinite_cost + np.sum(diagonal_cost))\n",
    "        \n",
    "        # Both diagrams only have one persistence point, the distance is the di\n",
    "        else:\n",
    "            return -gamma *np.abs(dgmx[0] - dgmy[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641b480-17eb-4a3b-b6b5-c5d1815ac76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphPersistenceGenerator:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    This class works in the following way:\n",
    "        \n",
    "        We rely on the creation of a custom filtration to preform persistent homology computations.\n",
    "        This filtration takes the form of a matrix which inherits the structure of G, i.e.  \n",
    "    \n",
    "        The diagonal of this matrix will be given by node values. If G has an edge between nodes \n",
    "        (i,j), then we set filtration[i,j] to be the maximum node value between i and j. If there is not\n",
    "        an edge between nodes (i,j), then we treat the \"distance\" as infinite.\n",
    "\n",
    "        Persistent homology calculations are \n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, G):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize the adjacency matrix\n",
    "        G : networkx graph\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        adj = nx.adjacency_matrix(G)\n",
    "        h, w = adj.shape\n",
    "        \n",
    "        # Get indices of edges, determined by the structure on G\n",
    "        # edge_idx, edge_idy = adj.nonzero(). Of course, the adjacency matrix is symmertric; \n",
    "        # for efficiency, we choose to remember only the lower diagonal indcies to update the filtration. \n",
    "\n",
    "        inds = np.vstack([*adj.nonzero()]).T\n",
    "\n",
    "        full_edge_idx, full_edge_idy = inds[:, 0], inds[:, 1]\n",
    "        \n",
    "        lower_diag_inds = inds[np.argmax(inds, axis=1) > 0, :]\n",
    "        edge_idx, edge_idy = lower_diag_inds[:, 0], lower_diag_inds[:, 1]\n",
    "        \n",
    "        # Indices of nodes, which are on the diagonal of the filtration matrix \n",
    "        node_idx, node_idy = np.arange(0,h), np.arange(0,h)\n",
    "\n",
    "        # Combined indices of edges and nodes. Note that we need to account for the symmetry of the adjacency\n",
    "        # matrix here, which is why we are using the full_edge_idx and full_edge_idy here.\n",
    "        idx_x, idx_y = np.concatenate([full_edge_idx, node_idx]), np.concatenate([full_edge_idy, node_idy])\n",
    "        self.filtration_inds = list(zip(np.concatenate([edge_idx, node_idx]), np.concatenate([edge_idy, node_idy])))\n",
    "        \n",
    "        self.filtration = scipy.sparse.csr_matrix((np.ones(len(idx_x)), (idx_x, idx_y)), shape=(h,w))\n",
    "\n",
    "    def update(self, new_node_values):\n",
    "        \n",
    "        \"\"\"\n",
    "        Update edge weights/node values with new_node_values\n",
    "        For example, suppose the current state of self.filtration is \n",
    "        \n",
    "        [[0.1, 0.4, 0.0], \n",
    "         [0.4, 0.4, 0.4],\n",
    "         [0.0, 0.4, 0.1]]\n",
    "        \n",
    "        and the indicies we replace are specified as [[0,0], [0,1], [1,1], [2,1], [2,2]].\n",
    "        \n",
    "        If new_node_values = [0.05, 0.1, 0.25], \n",
    "        calling self.update() will change self.filtration to\n",
    "        \n",
    "        [[0.05, 0.1, 0.0], \n",
    "         [0.1, 0.1, 0.25],\n",
    "         [0.0, 0.25, 0.25]]\n",
    "\n",
    "\n",
    "        Note that for a given edge in the filtration, which is specified by indices [i,j], the \n",
    "        edge will be \"created\" at max(node_value(i), node_value(j)) when we want to \n",
    "        calculate the persistence diagram of the graph. \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        for (i,j) in self.filtration_inds:\n",
    "            new_edge_weight = np.maximum(new_node_values[i], new_node_values[j])\n",
    "            self.filtration[i,j] = new_edge_weight\n",
    "            self.filtration[j,i] = new_edge_weight\n",
    "        \n",
    "        \n",
    "    def compute_PH(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Compute the 0-dimensional persistent homology for the current filtration.\n",
    "        \n",
    "        Ripser returns a list of persistence diagram points, which we need to convert to a 2-D numpy array to\n",
    "        use in gudhi's wasserstein_distance function.\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.squeeze(np.array(ripser.ripser(self.filtration, maxdim=0, distance_matrix=True)['dgms']))\n",
    "\n",
    "\n",
    "    def __call__(self, new_node_values):\n",
    "        self.update(new_node_values)\n",
    "        return self.compute_PH()\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74479bb-6f7f-4b28-85ad-7b5750fabf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EigenvectorRandomWalkMetropolis:\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Graph laplacian eigenvector Random Walk Metropolis Class\n",
    "    \n",
    "    parameters: \n",
    "\n",
    "        G : networkx graph\n",
    "        \n",
    "        target : the target persistence diagram (n x 2 numpy array)\n",
    "        \n",
    "        start : the starting point for mcmc\n",
    "\n",
    "        step : Proposed moves follow a normal distribution with mean = 0 and std = step.\n",
    "        \n",
    "        nev : number of graph laplacian eigenvectors to take - this is the dimension \n",
    "              of the search space\n",
    "              \n",
    "        MIN/MAX : bounds of the search space \n",
    "\n",
    "        \n",
    "        gamma : scaling factor for 2-wasserstein distance\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, G, target, start, step, nev, MIN=-np.inf, MAX=np.inf, gamma=1.0):\n",
    "\n",
    "        laplacian = nx.normalized_laplacian_matrix(G).toarray()\n",
    "        _, eigenvectors = np.linalg.eigh(laplacian)\n",
    "\n",
    "        self.phi = eigenvectors[:, 0:nev]\n",
    "        self.gpg = GraphPersistenceGenerator(G)\n",
    "        self.target = target\n",
    "        self.current_location = start\n",
    "        self.step = step\n",
    "        self.gamma = gamma\n",
    "        self.nev = nev\n",
    "        self.current_p = self.density_func(start)\n",
    "        self.num_accepted = 0\n",
    "        self.lower_bound = MIN\n",
    "        self.upper_bound = MAX\n",
    "\n",
    "    def density_func(self, x):\n",
    "\n",
    "        \"\"\" \n",
    "        \n",
    "        x is assumed to be a vector of coefficients in this case, but\n",
    "        different varieties of density functions can replace this\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        output_pd = self.gpg(self.phi @ x)\n",
    "        return two_wasserstein(output_pd, self.target, self.gamma)\n",
    "    \n",
    "    def sample(self):\n",
    "\n",
    "        \"\"\"Preform one iteration of MCMC\"\"\"\n",
    "        \n",
    "        proposed_move = np.random.normal(loc=0.0, scale=step, size=self.nev) + self.current_location\n",
    "        if np.all(proposed_move >= self.lower_bound) & np.all(proposed_move <= self.upper_bound):\n",
    "            proposed_move_density = self.density_func(proposed_move)\n",
    "            \n",
    "            if np.random.uniform() < np.exp(proposed_move_density - self.current_p):\n",
    "                \n",
    "                # the move is accepted, update the current location and density, and\n",
    "                # increment the numeber of accepted moves by one.\n",
    "                self.current_p = proposed_move_density\n",
    "                self.current_location = proposed_move\n",
    "                self.num_accepted += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf6a81-7f4d-4a9e-a6ec-72cea039d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMC:\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Runs MCMC over multiple iterations, and keeps track of paramter locations and densities. \n",
    "    Also inlcudes functionality for plotting trace plots \n",
    "\n",
    "        - model should be one of the RWM models in this file.\n",
    "        - dim is the dimension of the search space\n",
    "        - gamma is the 2-wasserstein penalty term used in the density function, defaults to 1.0\n",
    "        - iterations - number of mcmc iterations to run\n",
    "        - burnin - burnin period\n",
    "        - seed - random seed for reproducibility.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, dim, gamma=1.0, iterations=100000, burnin=10000, seed=42):\n",
    "\n",
    "        self.model = model\n",
    "        \n",
    "        self.iterations = iterations\n",
    "        self.burnin = burnin\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        self.seed = seed\n",
    "\n",
    "        self.sim = np.zeros((dim, iterations-burnin))\n",
    "        self.losses = np.zeros(iterations-burnin)\n",
    "\n",
    "        # If we are using a penalty term when calculating the 2-wasserstein distance, include it\n",
    "        # here to scale densities to calculate various performance metrics.\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def run(self):\n",
    "\n",
    "        \"\"\" \n",
    "        Run MCMC for the specified number of iterations\n",
    "        \"\"\"\n",
    "        \n",
    "        np.random.seed(self.seed)\n",
    "        for i in tqdm.tqdm(range(self.iterations)):\n",
    "\n",
    "            self.model.sample()\n",
    "\n",
    "            if i - self.burnin >= 0:\n",
    "                self.sim[:, i - burnin] = model.current_location\n",
    "                self.losses[i - burnin] = - model.current_p / self.gamma\n",
    "\n",
    "        print(f\"Percentage of moves accepted : {model.num_accepted / self.iterations * 100.0} %\")\n",
    "        print(f\"Best Loss: {np.min(self.losses)}\")\n",
    "\n",
    "\n",
    "    \n",
    "    def trace_plots(self, inds=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Create trace plots\n",
    "        \n",
    "        inds : the parameters you want to see trace plots for - e.g, if you have \n",
    "               8 parameters, and you pass [0,1,2,3] to trace_plots, you will see \n",
    "               trace plots for the first 4 parameters. \n",
    "\n",
    "               Passing None will result in all trace plots being shown\n",
    "        \n",
    "        \"\"\"    \n",
    "        \n",
    "        if inds:\n",
    "            fig, axes = plt.subplots(len(inds), 1, layout='constrained')\n",
    "        else:\n",
    "            inds = range(self.sim.shape[0])\n",
    "            fig, axes = plt.subplots(self.sim.shape[0], 1, layout='constrained')\n",
    "        \n",
    "        for (i,indx) in enumerate(inds):\n",
    "            sns.lineplot(data=self.sim[i, :], ax=axes[i])        \n",
    "      \n",
    "        plt.show()\n",
    "\n",
    "    def density_plots(self, inds=None):\n",
    "        \"\"\"Create density plots, inds functions the same as in trace_plots\"\"\"\n",
    "        \n",
    "        if inds:\n",
    "            fig, axes = plt.subplots(len(inds), 1, layout='constrained')\n",
    "        else:\n",
    "            inds = range(self.sim.shape[0])\n",
    "            fig, axes = plt.subplots(self.sim.shape[0], 1, layout='constrained')\n",
    "        \n",
    "        for (i,indx) in enumerate(inds):\n",
    "            sns.kdeplot(data=self.sim[i, :], ax=axes[i]) \n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    def best_approximation(self):\n",
    "        \"\"\"Return the node values of the best apporximation found in the run\"\"\"\n",
    "        min_loss = np.argmin(self.losses)\n",
    "        best_coeff = self.sim[:, min_loss]\n",
    "        best_node_values = self.model.phi @ best_coeff\n",
    "\n",
    "        return best_node_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa4ba7-a8ea-4316-ac1a-a2f7f48717a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nev = 6\n",
    "iterations = 1000\n",
    "burnin = 100\n",
    "gamma = 40.0\n",
    "seed = 42\n",
    "\n",
    "num_nodes = 14\n",
    "node_prob = 0.2\n",
    "\n",
    "G = nx.erdos_renyi_graph(num_nodes, node_prob, seed=seed)\n",
    "laplacian = nx.normalized_laplacian_matrix(G).toarray()\n",
    "_, eigenvectors = np.linalg.eigh(laplacian)\n",
    "\n",
    "phi = eigenvectors[:, 0:nev]\n",
    "\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7460c2-a515-4da6-8eec-f05d1d92cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G, target, start, step, nev, MIN=-np.inf, MAX=np.inf, gamma=1.0\n",
    "\n",
    "np.random.seed(45)\n",
    "graph_persistence_generator = GraphPersistenceGenerator(G)\n",
    "target_node_values = np.random.rand(num_nodes)\n",
    "\n",
    "target = graph_persistence_generator(target_node_values)\n",
    "start = np.random.normal(size=nev)\n",
    "step = 0.1\n",
    "MIN = -np.inf\n",
    "MAX = np.inf\n",
    "\n",
    "model = EigenvectorRandomWalkMetropolis(G, target, start, step, nev, MIN, MAX, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5280285b-8873-44f5-aed0-884dd8f71389",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation = MCMC(model, nev, gamma, iterations, burnin, seed)\n",
    "simulation.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e22c2c-3f2e-484d-acb6-240bbe628bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.density_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dbacd0-1c7d-4b18-b77e-111b7feccb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_coeff = simulation.best_approximation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
